"""
AI-Powered CVE Exploit Discovery Pipeline
Uses GitHub MCP for repository discovery, then static analysis for filtering
"""

import logging
from typing import List, Dict, Optional
from datetime import datetime
from app.analyzers.github_mcp_client import GitHubMCPClient
from app.analyzers.ai_analyzer import AIAnalyzer
from app.analyzers.static_analyzer import StaticAnalyzer
from app.models import CVE, Exploit, ExploitSource, ExploitStatus
from app.models.base import get_db

logger = logging.getLogger(__name__)


class CVEExploitPipeline:
    """
    Main pipeline for discovering and analyzing CVE exploits.
    
    Architecture:
    - GitHub MCP Server: Official GitHub API tools (https://github.com/github/github-mcp-server)
    - AI Analyzer: AI model layer that intelligently uses MCP tools
    - Static Analyzer: Baseline static analysis on code
    - Filtering: Filter based on analysis results
    
    Pipeline stages:
    1. AI/MCP Search: AI generates queries, MCP searches GitHub
    2. AI Analysis: AI analyzes repositories for relevance
    3. Static Analysis: Baseline static analysis on code
    4. Filtering: Filter repositories based on static analysis results
    5. Save: Store results with metadata for dynamic analysis stage
    """
    
    def __init__(self, mcp_client: Optional[GitHubMCPClient] = None,
                 ai_analyzer: Optional[AIAnalyzer] = None):
        """
        Initialize the pipeline.
        
        Args:
            mcp_client: GitHub MCP client instance (optional, will create if not provided)
            ai_analyzer: AI analyzer instance (optional, will create if not provided)
        """
        # Initialize MCP client (connects to official GitHub MCP server)
        self.mcp_client = mcp_client or GitHubMCPClient()
        
        # Initialize AI analyzer (uses AI model to intelligently use MCP tools)
        self.ai_analyzer = ai_analyzer or AIAnalyzer(self.mcp_client)
        
        # Initialize static analyzer
        self.static_analyzer = StaticAnalyzer()
        
        # Filtering thresholds
        self.min_baseline_score = 50  # Minimum static analysis score
        self.min_confidence_score = 40  # Minimum AI confidence score
    
    async def process_cve(self, cve_id: str, limit: int = 20) -> Dict:
        """
        Process a CVE through the complete pipeline.
        
        Args:
            cve_id: CVE identifier (e.g., CVE-2024-12345)
            limit: Maximum number of repositories to initially discover
            
        Returns:
            Dictionary with processing results
        """
        logger.info(f"Starting AI-powered pipeline for {cve_id}")
        
        results = {
            'cve_id': cve_id,
            'started_at': datetime.utcnow().isoformat(),
            'stage_1_mcp_discovery': {},
            'stage_2_static_analysis': {},
            'stage_3_filtering': {},
            'stage_4_saved': {},
            'errors': []
        }
        
        try:
            # Stage 1: AI/MCP Repository Discovery
            logger.info(f"Stage 1: AI/MCP discovering repositories for {cve_id}")
            repositories = await self.ai_analyzer.search_repositories_for_cve(cve_id, limit=limit)
            results['stage_1_mcp_discovery'] = {
                'repositories_found': len(repositories),
                'repositories': repositories
            }
            
            if not repositories:
                logger.warning(f"No repositories found via AI/MCP for {cve_id}")
                return results
            
            # Stage 2: AI Repository Analysis
            logger.info(f"Stage 2: AI analyzing {len(repositories)} repositories")
            analyzed_repos = []
            for repo in repositories:
                try:
                    repo_url = repo.get('html_url', repo.get('url', ''))
                    analysis = await self.ai_analyzer.analyze_repository_with_ai(
                        repo_url,
                        cve_id
                    )
                    analyzed_repos.append({
                        'repository': repo,
                        'ai_analysis': analysis
                    })
                except Exception as e:
                    error_msg = f"Error analyzing {repo.get('html_url', 'unknown')}: {str(e)}"
                    logger.error(error_msg)
                    results['errors'].append(error_msg)
            
            results['stage_2_mcp_analysis'] = {
                'repositories_analyzed': len(analyzed_repos),
                'analyses': analyzed_repos
            }
            
            # Stage 3: Static Analysis on Exploit Files
            logger.info(f"Stage 3: Performing static analysis")
            static_analysis_results = []
            for repo_data in analyzed_repos:
                try:
                    # Get files via AI/MCP
                    repo_url = repo_data['repository'].get('html_url', '')
                    files = await self.ai_analyzer.get_repository_files(
                        repo_url,
                        cve_id
                    )
                    
                    # Perform static analysis on each file
                    for file_info in files:
                        file_content = file_info.get('content', '')
                        if not file_content:
                            continue
                        
                        language = file_info.get('language', 'unknown')
                        static_result = self.static_analyzer.analyze_code(
                            code=file_content,
                            language=language,
                            file_path=file_info.get('path')
                        )
                        
                        static_analysis_results.append({
                            'repository': repo_data['repository'],
                            'ai_analysis': repo_data['ai_analysis'],
                            'file_info': file_info,
                            'static_analysis': static_result
                        })
                        
                except Exception as e:
                    error_msg = f"Error in static analysis: {str(e)}"
                    logger.error(error_msg)
                    results['errors'].append(error_msg)
            
            results['stage_2_static_analysis'] = {
                'files_analyzed': len(static_analysis_results),
                'results': static_analysis_results
            }
            
            # Stage 4: Filtering based on static analysis
            logger.info(f"Stage 4: Filtering repositories based on static analysis")
            filtered_results = self._filter_by_static_analysis(static_analysis_results)
            results['stage_3_filtering'] = {
                'before_filtering': len(static_analysis_results),
                'after_filtering': len(filtered_results),
                'filtered_out': len(static_analysis_results) - len(filtered_results),
                'filtered_results': filtered_results
            }
            
            # Stage 5: Save to database and prepare for dynamic analysis
            logger.info(f"Stage 5: Saving {len(filtered_results)} exploits")
            saved_count = await self._save_for_dynamic_analysis(cve_id, filtered_results)
            results['stage_4_saved'] = {
                'exploits_saved': saved_count,
                'ready_for_dynamic_analysis': saved_count
            }
            
            results['completed_at'] = datetime.utcnow().isoformat()
            logger.info(f"Pipeline completed for {cve_id}: {saved_count} exploits saved and ready for dynamic analysis")
            
        except Exception as e:
            logger.error(f"Pipeline error for {cve_id}: {str(e)}")
            results['error'] = str(e)
        
        return results
    
    def _filter_by_static_analysis(self, static_results: List[Dict]) -> List[Dict]:
        """
        Filter repositories based on static analysis results.
        
        Filtering criteria:
        - Baseline score >= threshold
        - Syntax valid
        - AI confidence score >= threshold
        - Security risk level acceptable
        
        Args:
            static_results: List of static analysis results
            
        Returns:
            Filtered list of results ready for dynamic analysis
        """
        filtered = []
        
        for result in static_results:
            static_analysis = result.get('static_analysis', {})
            ai_analysis = result.get('ai_analysis', {})
            
            # Check baseline score
            baseline_score = static_analysis.get('baseline_score', 0)
            if baseline_score < self.min_baseline_score:
                logger.debug(f"Filtered out: baseline score {baseline_score} < {self.min_baseline_score}")
                continue
            
            # Check syntax validity
            if not static_analysis.get('syntax_valid', False):
                logger.debug("Filtered out: invalid syntax")
                continue
            
            # Check AI confidence
            ai_confidence = ai_analysis.get('relevance_score', 0)
            if ai_confidence < self.min_confidence_score:
                logger.debug(f"Filtered out: AI confidence {ai_confidence} < {self.min_confidence_score}")
                continue
            
            # Check security risk (optional - might want high risk exploits)
            security = static_analysis.get('security_analysis', {})
            risk_level = security.get('risk_level', 'low')
            # Don't filter by risk - we want to analyze all valid exploits
            
            # Passed all filters
            filtered.append(result)
        
        logger.info(f"Filtered {len(static_results)} -> {len(filtered)} results")
        return filtered
    
    async def _save_for_dynamic_analysis(self, cve_id: str, filtered_results: List[Dict]) -> int:
        """
        Save filtered results to database with all metadata needed for dynamic analysis.
        
        Args:
            cve_id: CVE identifier
            filtered_results: Filtered analysis results
            
        Returns:
            Number of exploits saved
        """
        saved_count = 0
        db = next(get_db())
        
        try:
            # Get CVE from database
            cve = db.query(CVE).filter(CVE.cve_id == cve_id).first()
            if not cve:
                logger.warning(f"CVE {cve_id} not found in database")
                return 0
            
            for result in filtered_results:
                try:
                    repo = result['repository']
                    ai_analysis = result['ai_analysis']
                    file_info = result['file_info']
                    static_analysis = result['static_analysis']
                    
                    # Extract README instructions via AI/MCP
                    repo_url = repo.get('html_url', repo.get('url', ''))
                    readme_instructions = await self.ai_analyzer.extract_readme_instructions(
                        repo_url,
                        file_info.get('path', '')
                    )
                    
                    # Create exploit record with all metadata for dynamic analysis
                    exploit = self._create_exploit_record(
                        cve=cve,
                        repo=repo,
                        file_info=file_info,
                        ai_analysis=ai_analysis,
                        static_analysis=static_analysis,
                        readme_instructions=readme_instructions
                    )
                    
                    db.add(exploit)
                    saved_count += 1
                    
                except Exception as e:
                    logger.error(f"Error saving exploit: {str(e)}")
                    continue
            
            db.commit()
            
        except Exception as e:
            db.rollback()
            logger.error(f"Error saving exploits: {str(e)}")
            raise
        finally:
            db.close()
        
        return saved_count
    
    def _create_exploit_record(self, cve, repo: Dict, file_info: Dict,
                              ai_analysis: Dict, static_analysis: Dict,
                              readme_instructions: Optional[str]) -> Exploit:
        """
        Create Exploit database record with all metadata for dynamic analysis.
        
        Args:
            cve: CVE database object
            repo: Repository information from MCP
            file_info: File information from MCP
            ai_analysis: AI analysis results from MCP
            static_analysis: Static analysis results
            readme_instructions: README instructions from MCP
            
        Returns:
            Exploit database object ready for dynamic analysis
        """
        file_content = file_info.get('content', '')
        language = file_info.get('language', 'unknown')
        file_path = file_info.get('path', '')
        
        # Extract title
        title = file_path.split('/')[-1] if '/' in file_path else file_info.get('name', 'Unknown')
        if len(title) > 500:
            title = title[:497] + '...'
        
        # Calculate scores
        baseline_score = static_analysis.get('baseline_score', 0)
        ai_confidence = ai_analysis.get('relevance_score', 0)
        combined_confidence = int((baseline_score * 0.6 + ai_confidence * 0.4))
        
        # Prepare metadata for dynamic analysis stage
        raw_data = {
            # Stage 1: MCP/AI Discovery
            'mcp_discovery': {
                'repository': repo,
                'ai_analysis': ai_analysis,
                'discovery_method': 'github_mcp'
            },
            
            # Stage 2: Static Analysis
            'static_analysis': static_analysis,
            'baseline_score': baseline_score,
            
            # Stage 3: Ready for Dynamic Analysis
            'readme_instructions': readme_instructions,
            'execution_requirements': static_analysis.get('execution_requirements', {}),
            'dependencies': static_analysis.get('dependencies', []),
            'file_info': {
                'path': file_path,
                'language': language,
                'size': len(file_content)
            },
            
            # Pipeline metadata
            'pipeline_stage': 'ready_for_dynamic_analysis',
            'pipeline_version': '2.0',
            'processed_at': datetime.utcnow().isoformat(),
            'filtered': True,  # Indicates this passed filtering stage
        }
        
        exploit = Exploit(
            cve_id=cve.id,
            title=title,
            description=f"Exploit code discovered via MCP/AI from {repo.get('full_name', 'unknown')}",
            author=repo.get('owner', {}).get('login', '') if isinstance(repo.get('owner'), dict) else None,
            source=ExploitSource.GITHUB,
            source_url=file_info.get('url', repo.get('url', '')),
            source_id=str(repo.get('id', '')),
            exploit_code=file_content,
            file_path=file_path,
            file_type=language,
            programming_language=language,
            validation_status=ExploitStatus.PENDING,
            github_stars=repo.get('stargazers_count', 0),
            github_forks=repo.get('forks_count', 0),
            github_updated=datetime.fromisoformat(repo['updated_at']) if repo.get('updated_at') else None,
            github_language=repo.get('language'),
            confidence_score=combined_confidence,
            popularity_score=min(100, (repo.get('stargazers_count', 0) // 10) + (repo.get('forks_count', 0) // 5)),
            tags=repo.get('topics', []),
            requirements=static_analysis.get('execution_requirements', {}).get('dependencies', []),
            raw_data=raw_data
        )
        
        return exploit
    
    async def process_multiple_cves(self, cve_ids: List[str], limit_per_cve: int = 20) -> Dict:
        """
        Process multiple CVEs through the pipeline.
        
        Args:
            cve_ids: List of CVE identifiers
            limit_per_cve: Maximum repositories per CVE
            
        Returns:
            Summary of processing results
        """
        summary = {
            'total_cves': len(cve_ids),
            'processed': 0,
            'total_exploits_saved': 0,
            'results': []
        }
        
        for cve_id in cve_ids:
            try:
                result = await self.process_cve(cve_id, limit=limit_per_cve)
                summary['processed'] += 1
                summary['total_exploits_saved'] += result.get('stage_4_saved', {}).get('exploits_saved', 0)
                summary['results'].append(result)
            except Exception as e:
                logger.error(f"Error processing {cve_id}: {str(e)}")
                summary['results'].append({
                    'cve_id': cve_id,
                    'error': str(e)
                })
        
        return summary
